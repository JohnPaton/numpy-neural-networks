# numpy-neural-networks
A collection of notebooks to organize my thoughts as I dive into deep learning. Thanks to Eric Postma for suggesting this learning path.

Links to nbviewer (for nicer LaTeX rendering):

1. [Single Layer Perceptron](https://nbviewer.jupyter.org/github/JohnPaton/numpy-neural-networks/blob/master/01-single-layer-perceptron.ipynb)

2. [Multi-Layer Perceptron](https://nbviewer.jupyter.org/github/JohnPaton/numpy-neural-networks/blob/master/02-multi-layer-perceptron.ipynb)

3. [Improved training methods](https://nbviewer.jupyter.org/github/JohnPaton/numpy-neural-networks/blob/master/03-better-training.ipynb): Mini-batches, momentum, and learning rate decay

4. [Preventing overfitting](https://nbviewer.jupyter.org/github/JohnPaton/numpy-neural-networks/blob/master/04-regularization-dropout.ipynb): weight regularization and dropout

5. Visualizing activations (planned)

6. Convolution (planned)

7. Recurrence (planned)
